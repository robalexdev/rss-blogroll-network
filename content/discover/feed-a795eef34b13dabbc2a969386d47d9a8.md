---
title: Eli Bendersky's website
date: "2025-04-13T18:02:41-07:00"
description: ""
params:
  feedlink: https://eli.thegreenplace.net/feeds/all.atom.xml
  feedtype: atom
  feedid: a795eef34b13dabbc2a969386d47d9a8
  websites:
    https://eli.thegreenplace.net/: true
  blogrolls: []
  in_blogrolls:
  - title: RSS feeds from Minifeed.net
    description: ""
    id: 83b59248e9346428c889eb03522b4297
  recommended: []
  recommender: []
  categories:
  - Machine Learning
  - Math
  - misc
  relme: {}
  last_post_title: Cross-entropy and KL divergence
  last_post_description: |-
    Cross-entropy is widely used in modern ML to compute the loss for classification
    tasks. This post is a brief overview of the math behind it and a related
    concept called Kullback-Leibler (KL)
  last_post_date: "2025-04-13T18:02:41-07:00"
  last_post_link: https://eli.thegreenplace.net/2025/cross-entropy-and-kl-divergence/
  last_post_categories:
  - Machine Learning
  - Math
  - misc
  last_post_language: ""
  last_post_guid: ffa4357210c4e8b04d15064121785cad
  score_criteria:
    cats: 0
    description: 0
    feedlangs: 0
    hasContent: 3
    hasPosts: 3
    postcats: 3
    promoted: 5
    promotes: 0
    relme: 0
    title: 3
    website: 2
  score: 19
  ispodcast: false
  isnoarchive: false
  innetwork: true
  language: ""
  postcount: 10
  avgpostlen: 294
---
